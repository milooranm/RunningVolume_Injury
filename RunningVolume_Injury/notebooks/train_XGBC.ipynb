{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d579903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62eab895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize2(row, mean_df, std_df, athlete_id):\n",
    "    mu = mean_df.loc[athlete_id]\n",
    "    su = std_df.loc[athlete_id]\n",
    "    z = (row - mu)/su\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ed5b7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanStd(data):\n",
    "    mean = data[data['injury'] == 0].groupby('Athlete ID').mean()\n",
    "    std = data[data['injury'] == 0].groupby('Athlete ID').std()\n",
    "    std.replace(to_replace=0.0, value=0.01, inplace=True)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d47278be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBalancedSubset(X_train, samplesPerClass):\n",
    "    healthySet   = pd.DataFrame()\n",
    "    unhealthySet = pd.DataFrame()\n",
    "    \n",
    "\n",
    "    stats = pd.DataFrame(X_train[['Athlete ID','injury']].groupby(['Athlete ID','injury']).size().reset_index(name='counts'))\n",
    "    stats = pd.DataFrame(stats[['Athlete ID']].groupby(['Athlete ID']).size().reset_index(name='counts'))\n",
    "    stats.drop(stats[stats['counts'] < 2].index, inplace=True)\n",
    "    athleteList = stats['Athlete ID'].unique()\n",
    "\n",
    "    samplesPerAthlete = int(np.floor(samplesPerClass) / len(athleteList))\n",
    "\n",
    "    for athlete in athleteList:\n",
    "        if unhealthySet.empty:\n",
    "            unhealthySet = X_train[(X_train['Athlete ID'] == athlete) & (X_train['injury'] == 0)].sample(samplesPerAthlete, replace=True)\n",
    "        else:\n",
    "            unhealthySet = pd.concat([unhealthySet, X_train[(X_train['Athlete ID'] == athlete) & (X_train['injury'] == 0)].sample(samplesPerAthlete,replace=True)], ignore_index=True)\n",
    "        if healthySet.empty:\n",
    "            healthySet = X_train[(X_train['Athlete ID'] == athlete) & (X_train['injury'] == 1)].sample(samplesPerAthlete, replace=True)\n",
    "        else:\n",
    "            healthySet = pd.concat([healthySet, X_train[(X_train['Athlete ID'] == athlete) & (X_train['injury'] == 1)].sample(samplesPerAthlete,replace=True)], ignore_index=True)\n",
    "\n",
    "\n",
    "    balancedSet = pd.concat([healthySet, unhealthySet], ignore_index=True)\n",
    "    return balancedSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c732058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparedata(df,test_athletes):\n",
    "\n",
    "    X_test_original = df[df['Athlete ID'].isin(test_athletes)].copy() # Keep a copy for normalization\n",
    "    X_train_original = df[~df['Athlete ID'].isin(test_athletes)].copy() # Keep a copy\n",
    "\n",
    "    X_train_means, X_train_std = getMeanStd(X_train_original)\n",
    "    X_test_means, X_test_std = getMeanStd(X_test_original)\n",
    "    X_train_balanced = getBalancedSubset(X_train_original.copy(), 2048)\n",
    "    \n",
    "    # Set target variable for testing and training\n",
    "    y_train = X_train_balanced['injury']\n",
    "    y_test = X_test_original['injury']\n",
    "\n",
    "    # Apply normalization to the balanced training data\n",
    "    X_train_norm = X_train_balanced.apply(lambda x: normalize2(x, X_train_means, X_train_std, x['Athlete ID']), axis=1)\n",
    "    X_train_norm = X_train_norm.drop(columns=['injury', 'Date', 'Athlete ID'], errors='ignore')\n",
    "\n",
    "    # Apply normalization to the test data using the testing statistics\n",
    "    # Note this is a source of data leakage! but the alternative is not feasible\n",
    "    X_test_norm = X_test_original.apply(lambda x: normalize2(x, X_test_means, X_test_std, x['Athlete ID']), axis=1)\n",
    "    X_test_norm = X_test_norm.drop(columns=['injury', 'Date', 'Athlete ID'], errors='ignore')\n",
    "\n",
    "\n",
    "    return y_train, y_test, X_train_norm, X_test_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6f7591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train):\n",
    "    xgbc = XGBClassifier()\n",
    "    xgbc.fit(X_train, y_train)\n",
    "    return xgbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e20ff11",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def confusion_matrix(y_test, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', annot_kws={\"size\": 16})\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659336eb",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dadd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfday = pd.read_csv('../data/raw/day_approach.csv')\n",
    "dfday.drop(list(dfday.filter(regex = 'perceived|sprinting|strength')), axis = 1, inplace = True)\n",
    "athletes = sorted(list(dfday['Athlete ID'].unique()))\n",
    "test_athletes = athletes[len(athletes) - 10:]\n",
    "y_train, y_test, X_train, X_test = preparedata(dfday, test_athletes)\n",
    "model = train_model(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2529042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
